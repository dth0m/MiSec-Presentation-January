{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiSec ML Use Case Demo\n",
    "This Jupyter notebook walks through a basic Machine Learning classification use case with meta data derived from a labeled set of PowerShell logs.  You will need Scikit-learn, matplotlib, and numpy installed.  Code can be ran using Canopy (https://www.enthought.com/product/canopy/), in a Docker jupyter/datascience-notebook (https://hub.docker.com/r/jupyter/datascience-notebook/), or any other environment with the required packages.\n",
    "\n",
    "The methodology presented has been ported from https://machinelearningmastery.com/machine-learning-in-python-step-by-step/.  After the data has been processed this is essentially the \"hello world\" of classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import re, math \n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn import cross_validation\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "Predictors2.txt contains calculated PowerShell metadata and a label that indicates whether the sample is malicious or benign.  There are 7 columns of data in a CSV format that indicate the uppercase/lowercase ratio, special character to total character ratio, alpha character to total character ratio, cosine similarity score, count of suspicious modules, count of malicious modules, and label.  The cosine similarity was implemented in python but the idea came from Lee Holmes at http://www.leeholmes.com/blog/2016/10/22/more-detecting-obfuscated-powershell/.  The specific module considered suspicious/malicious were derived using analyst judgement after reviewing a large quantity of events.  These two predictors are hand engineered and were ultimately removed for a better methodology of generating vocabulary frequency counts.  As predictors they worked very well but required ongoing maintenance which is not what we want when implementing an ML use case.  The last column is the label with 0 representing a benign record and 1 representing a suspicious record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "my_data = np.genfromtxt('predictors2.txt', delimiter=',', usecols= (0,1,2,3,4,5,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Train/Test/Validation data\n",
    "Traning/testing and validation data are required before we start experimenting with various models.  We need to split the data into a train and validation set of predictors and a train and validation set of labels.  The training set will be used for testing various models to determine which model is the most accurate.  The validation set will be used to test the data on previously unseen data in order to determine whether the training model is overfitting the data or whether the training set does not closely represent the entire population of events.  The output shows an example of the predictors and label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.77272727  0.17355372  0.25206612  0.36063873  0.          0.        ]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# predictors\n",
    "X = my_data[:, 0:6]\n",
    "print(X[1,:])\n",
    "\n",
    "#Label\n",
    "y = my_data[:,6]\n",
    "print(y[1])\n",
    "\n",
    "#generate train and validation data sets\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, y, test_size=validation_size, \\\n",
    "                                                                                random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definitions\n",
    "Each model and model label are added to a list which will be used for accuracy evaluation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Models\n",
    "models = []\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "Each model is evaluated for accuracy using 10 fold validation.  The output shows the average score and standard deviation of the scores.  RF and KNN algorithm are very similar in accuracy most often the most accurate with the test data.\n",
    "\n",
    "### Accuracy\n",
    "Accuracy is one evaluation criteria that shows what percentage of true positves and true negatives were predicted correctly.  (True Positive + True Negative)/Total Events=Accuracy.  This appears to be very good but our data is very skewed towards events that are not suspicious so a high accuracy could still be very bad.  If we guessed everything was benign we would still have an accuracy of almost 93%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF: 0.996402 (0.002062)\n",
      "LR: 0.987858 (0.004741)\n",
      "LDA: 0.975266 (0.006053)\n",
      "KNN: 0.997302 (0.002621)\n",
      "CART: 0.995728 (0.002347)\n",
      "NB: 0.973472 (0.005103)\n",
      "SVM: 0.987634 (0.005438)\n"
     ]
    }
   ],
   "source": [
    "scoring = 'accuracy'\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results\n",
    "Below is a box plot that shows the accuracy results of the various algorithms.  The scale is limited to an accuracy of 96% and above so all of the algorithms were fairly accurate.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbd1a4012e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision\n",
    "Precision shows what percentage of positive (suspicious events) predictions were truely suspicious out of all the positive predictions.  This can help us determine how much trust to put in positive predictions but it doesn't tell us how many times it misses a positive prediction (false negative).  This metric answers the question: What percentage of suspicoius classifications are truely suspicious.\n",
    "\n",
    "\n",
    "True Positive/(True Positive + False Positive) = Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF: 0.982129 (0.022188)\n",
      "LR: 0.966582 (0.037036)\n",
      "LDA: 0.816453 (0.071596)\n",
      "KNN: 0.975818 (0.025927)\n",
      "CART: 0.946119 (0.058327)\n",
      "NB: 0.693118 (0.052446)\n",
      "SVM: 0.980486 (0.031000)\n"
     ]
    }
   ],
   "source": [
    "scoring = 'precision'\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall\n",
    "Recall helps determine how much we can trust the algorithm to catch all suspicious events.  This metric answers the questions: What percentage of truely suspicious events were classified as suspicious.\n",
    "\n",
    "True Positive/(True Positive + False Negative) = Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF: 0.963723 (0.034175)\n",
      "LR: 0.791953 (0.083966)\n",
      "LDA: 0.663084 (0.077516)\n",
      "KNN: 0.975433 (0.034415)\n",
      "CART: 0.963723 (0.034175)\n",
      "NB: 0.848044 (0.067814)\n",
      "SVM: 0.775720 (0.098513)\n"
     ]
    }
   ],
   "source": [
    "scoring = 'recall'\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1\n",
    "The F1 score is a scoring metric that takes both recall and precision into consideration.  If you need a good mix of precision and recall then this is a good choice.\n",
    "\n",
    "F1 = 2 * ((precision * recall)/(precision + recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF: 0.972752 (0.022402)\n",
      "LR: 0.867563 (0.052916)\n",
      "LDA: 0.728654 (0.058884)\n",
      "KNN: 0.975165 (0.022398)\n",
      "CART: 0.949604 (0.033379)\n",
      "NB: 0.761196 (0.047634)\n",
      "SVM: 0.862240 (0.064523)\n"
     ]
    }
   ],
   "source": [
    "scoring = 'f1'\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Validation Set\n",
    "The algorithm needs to be tested on a set of data that it wasn't trained on to get a more realistic accuracy number.  Earlier 20% of the data was set aside for validation and the accuracy is shown below.  \n",
    "\n",
    "### Confusion Matrix\n",
    "The confusion matrix is a common way to present machine learning classification data.  In binary classification this will look like a 2x2 matrix.  The first row shows the count of truely benign events and the second row shows count of truely suspicous events.  The first column represents the quantity of benign predictions and the second column shows the predicted suspicious events.  Moving clockwise from the upper left we have true positive, false positive, true negative, false negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1056    1]\n",
      " [   3   53]]\n",
      "0.996406109614\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      1057\n",
      "        1.0       0.98      0.95      0.96        56\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make Predictions\n",
    "# Make predictions on validation dataset\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, Y_train)\n",
    "predictions = rf.predict(X_validation)\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions\n",
    "Making predictions is easy.  Just pass the event metadata to rf.predict and the model will output a 0 for benign and 1 for suspicious.  You can see a sample record from the validation set, the predicted output from the algorithm, and the true outcome from the labeled validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.22764228  0.140625    0.58984375  0.7865722   0.          0.        ]\n",
      "[ 0.]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(X_validation[1])\n",
    "print(rf.predict(X_validation[1].reshape(1,-1)))\n",
    "print(Y_validation[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "The values that were used to determine the Suspicious/Malicious module count had to be update to get good results on the validation set and increse the recall score.  This is not optimal since it will need to be updated manually over time.  A better solution is to vectorize the PowerShell events and generate a vocabulary that can be used as a large quantity of predictors.  The machine learning algorithm can take this data, learn, and weight terms to determine which terms typically represent suspicious events and which represent malicious events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 4, 'quick': 3, 'brown': 0, 'fox': 1, 'john': 2}\n",
      "[[0 0 0 0 1]\n",
      " [0 0 0 1 1]\n",
      " [1 0 0 1 1]\n",
      " [1 1 0 1 1]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 0 2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "sample = ['the', 'the quick', 'the quick brown', 'the quick brown fox', 'john', 'the the']\n",
    "vec = CountVectorizer()\n",
    "data = vec.fit_transform(sample).toarray()\n",
    "print(vec.vocabulary_)\n",
    "print(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
